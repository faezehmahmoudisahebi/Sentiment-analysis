{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading - visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    11104\n",
      "2     8572\n",
      "1     7671\n",
      "Name: sentiment, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('D:\\Data\\sentiment.csv')\n",
    "data = data.dropna()\n",
    "X = data['selected_text']\n",
    "y = data['sentiment']\n",
    "print(y.value_counts())\n",
    "sns.countplot(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text cleaning \n",
    "#### Removing stopwords, punctuation signs, url pattern and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    r = re.findall('@[\\w]*', text)\n",
    "    \n",
    "    for w in r:\n",
    "        text = text.replace(w, ' ')\n",
    "    text = text.replace('[^a-zA-Z#]', '')\n",
    "    text = ' '.join([word for word in text.split() if len(word) > 3])\n",
    "    \n",
    "    text = re.sub(r'\\$%,.\\:\\?', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    words = text.split(\" \")\n",
    "    words = [lemma.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    text = ' '.join(words) \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mahmoudi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mahmoudi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.apply(lambda x: transform_text(x))\n",
    "\n",
    "\n",
    "max_words = 5000\n",
    "max_len = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "tweets = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tweets, y, test_size = 0.3)\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   0,   7],\n",
       "       [  0,   0,   0, ...,   0,   0, 236],\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,   0,   0,   1],\n",
       "       [  0,   0,   0, ...,   0,   0, 360],\n",
       "       [  0,   0,   0, ...,   7, 424, 461]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 26s 130ms/step - loss: 0.9678 - accuracy: 0.5217 - val_loss: 0.8421 - val_accuracy: 0.5995\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 19s 124ms/step - loss: 0.7385 - accuracy: 0.7241 - val_loss: 0.6726 - val_accuracy: 0.7467\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 18s 123ms/step - loss: 0.5827 - accuracy: 0.7801 - val_loss: 0.5946 - val_accuracy: 0.7609\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 20s 135ms/step - loss: 0.5028 - accuracy: 0.8046 - val_loss: 0.5712 - val_accuracy: 0.7707\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 23s 151ms/step - loss: 0.4564 - accuracy: 0.8239 - val_loss: 0.5691 - val_accuracy: 0.7718\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 23s 156ms/step - loss: 0.4274 - accuracy: 0.8346 - val_loss: 0.5752 - val_accuracy: 0.7762\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 23s 150ms/step - loss: 0.4052 - accuracy: 0.8435 - val_loss: 0.5880 - val_accuracy: 0.7736\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 22s 147ms/step - loss: 0.3889 - accuracy: 0.8500 - val_loss: 0.6020 - val_accuracy: 0.7655\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 23s 154ms/step - loss: 0.3770 - accuracy: 0.8529 - val_loss: 0.6124 - val_accuracy: 0.7701\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 22s 150ms/step - loss: 0.3684 - accuracy: 0.8554 - val_loss: 0.6285 - val_accuracy: 0.7718\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 22s 150ms/step - loss: 0.3593 - accuracy: 0.8600 - val_loss: 0.6395 - val_accuracy: 0.7677\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 23s 150ms/step - loss: 0.3538 - accuracy: 0.8611 - val_loss: 0.6568 - val_accuracy: 0.7631\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 23s 151ms/step - loss: 0.3481 - accuracy: 0.8644 - val_loss: 0.6656 - val_accuracy: 0.7631\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 23s 150ms/step - loss: 0.3423 - accuracy: 0.8661 - val_loss: 0.6742 - val_accuracy: 0.7600\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 22s 148ms/step - loss: 0.3400 - accuracy: 0.8655 - val_loss: 0.6921 - val_accuracy: 0.7605\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 22s 147ms/step - loss: 0.3332 - accuracy: 0.8708 - val_loss: 0.7007 - val_accuracy: 0.7576\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 22s 147ms/step - loss: 0.3313 - accuracy: 0.8705 - val_loss: 0.7055 - val_accuracy: 0.7544\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 21s 143ms/step - loss: 0.3244 - accuracy: 0.8725 - val_loss: 0.7252 - val_accuracy: 0.7601\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 32s 215ms/step - loss: 0.3213 - accuracy: 0.8741 - val_loss: 0.7293 - val_accuracy: 0.7584\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 55s 369ms/step - loss: 0.3180 - accuracy: 0.8744 - val_loss: 0.7337 - val_accuracy: 0.7595\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 49s 329ms/step - loss: 0.3138 - accuracy: 0.8773 - val_loss: 0.7326 - val_accuracy: 0.7576\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 50s 334ms/step - loss: 0.3112 - accuracy: 0.8781 - val_loss: 0.7498 - val_accuracy: 0.7564\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 46s 304ms/step - loss: 0.3061 - accuracy: 0.8794 - val_loss: 0.7626 - val_accuracy: 0.7509\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 47s 311ms/step - loss: 0.3008 - accuracy: 0.8817 - val_loss: 0.7727 - val_accuracy: 0.7520\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 42s 277ms/step - loss: 0.2964 - accuracy: 0.8843 - val_loss: 0.7823 - val_accuracy: 0.7567\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 46s 305ms/step - loss: 0.2966 - accuracy: 0.8828 - val_loss: 0.7960 - val_accuracy: 0.7565\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.2909 - accuracy: 0.8852 - val_loss: 0.8054 - val_accuracy: 0.7472\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 48s 318ms/step - loss: 0.2877 - accuracy: 0.8857 - val_loss: 0.8178 - val_accuracy: 0.7571\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 48s 322ms/step - loss: 0.2843 - accuracy: 0.8878 - val_loss: 0.8186 - val_accuracy: 0.7489\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 30s 197ms/step - loss: 0.2814 - accuracy: 0.8883 - val_loss: 0.8329 - val_accuracy: 0.7509\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 23s 152ms/step - loss: 0.2827 - accuracy: 0.8865 - val_loss: 0.8376 - val_accuracy: 0.7504\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 24s 158ms/step - loss: 0.2786 - accuracy: 0.8888 - val_loss: 0.8487 - val_accuracy: 0.7517\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 24s 163ms/step - loss: 0.2762 - accuracy: 0.8893 - val_loss: 0.8516 - val_accuracy: 0.7522\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 25s 165ms/step - loss: 0.2731 - accuracy: 0.8911 - val_loss: 0.8677 - val_accuracy: 0.7531\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 51s 341ms/step - loss: 0.2734 - accuracy: 0.8908 - val_loss: 0.8810 - val_accuracy: 0.7525\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 55s 367ms/step - loss: 0.2721 - accuracy: 0.8908 - val_loss: 0.8808 - val_accuracy: 0.7498\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 56s 375ms/step - loss: 0.2680 - accuracy: 0.8932 - val_loss: 0.8968 - val_accuracy: 0.7526\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 54s 360ms/step - loss: 0.2664 - accuracy: 0.8917 - val_loss: 0.8892 - val_accuracy: 0.7484\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 48s 317ms/step - loss: 0.2639 - accuracy: 0.8936 - val_loss: 0.8983 - val_accuracy: 0.7458\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 45s 300ms/step - loss: 0.2656 - accuracy: 0.8936 - val_loss: 0.9002 - val_accuracy: 0.7499\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 46s 307ms/step - loss: 0.2605 - accuracy: 0.8974 - val_loss: 0.9106 - val_accuracy: 0.7439\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 23s 155ms/step - loss: 0.2608 - accuracy: 0.8948 - val_loss: 0.9244 - val_accuracy: 0.7443\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 23s 152ms/step - loss: 0.2576 - accuracy: 0.8971 - val_loss: 0.9187 - val_accuracy: 0.7453\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 22s 149ms/step - loss: 0.2586 - accuracy: 0.8956 - val_loss: 0.9232 - val_accuracy: 0.7348\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 22s 147ms/step - loss: 0.2546 - accuracy: 0.8970 - val_loss: 0.9362 - val_accuracy: 0.7438\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 26s 172ms/step - loss: 0.2537 - accuracy: 0.8973 - val_loss: 0.9401 - val_accuracy: 0.7469\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 48s 321ms/step - loss: 0.2556 - accuracy: 0.8978 - val_loss: 0.9425 - val_accuracy: 0.7475\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 47s 313ms/step - loss: 0.2535 - accuracy: 0.8962 - val_loss: 0.9477 - val_accuracy: 0.7439\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 47s 314ms/step - loss: 0.2515 - accuracy: 0.8989 - val_loss: 0.9644 - val_accuracy: 0.7450\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 43s 285ms/step - loss: 0.2500 - accuracy: 0.8981 - val_loss: 0.9649 - val_accuracy: 0.7385\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 48s 321ms/step - loss: 0.2504 - accuracy: 0.8994 - val_loss: 0.9654 - val_accuracy: 0.7344\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 46s 309ms/step - loss: 0.2474 - accuracy: 0.8987 - val_loss: 0.9680 - val_accuracy: 0.7439\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 46s 305ms/step - loss: 0.2464 - accuracy: 0.9016 - val_loss: 0.9734 - val_accuracy: 0.7415\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 45s 301ms/step - loss: 0.2463 - accuracy: 0.8982 - val_loss: 0.9819 - val_accuracy: 0.7417\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 45s 302ms/step - loss: 0.2465 - accuracy: 0.8995 - val_loss: 0.9813 - val_accuracy: 0.7433\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 45s 302ms/step - loss: 0.2436 - accuracy: 0.9008 - val_loss: 0.9914 - val_accuracy: 0.7402\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 44s 293ms/step - loss: 0.2434 - accuracy: 0.9012 - val_loss: 0.9934 - val_accuracy: 0.7430\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 45s 303ms/step - loss: 0.2457 - accuracy: 0.8986 - val_loss: 1.0031 - val_accuracy: 0.7425\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 46s 307ms/step - loss: 0.2418 - accuracy: 0.9013 - val_loss: 1.0087 - val_accuracy: 0.7367\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 41s 275ms/step - loss: 0.2424 - accuracy: 0.9012 - val_loss: 1.0167 - val_accuracy: 0.7395\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 43s 291ms/step - loss: 0.2416 - accuracy: 0.9019 - val_loss: 1.0069 - val_accuracy: 0.7393\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 38s 251ms/step - loss: 0.2400 - accuracy: 0.9023 - val_loss: 1.0128 - val_accuracy: 0.7377\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 42s 281ms/step - loss: 0.2371 - accuracy: 0.9024 - val_loss: 1.0237 - val_accuracy: 0.7391\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 44s 292ms/step - loss: 0.2363 - accuracy: 0.9018 - val_loss: 1.0285 - val_accuracy: 0.7395\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 41s 275ms/step - loss: 0.2366 - accuracy: 0.9027 - val_loss: 1.0385 - val_accuracy: 0.7428\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 0.2381 - accuracy: 0.9013 - val_loss: 1.0397 - val_accuracy: 0.7360\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 43s 290ms/step - loss: 0.2351 - accuracy: 0.9041 - val_loss: 1.0470 - val_accuracy: 0.7414\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 45s 303ms/step - loss: 0.2356 - accuracy: 0.9029 - val_loss: 1.0472 - val_accuracy: 0.7359\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 43s 290ms/step - loss: 0.2350 - accuracy: 0.9024 - val_loss: 1.0500 - val_accuracy: 0.7376\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 45s 301ms/step - loss: 0.2326 - accuracy: 0.9031 - val_loss: 1.0586 - val_accuracy: 0.7402\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 41s 272ms/step - loss: 0.2319 - accuracy: 0.9049 - val_loss: 1.0584 - val_accuracy: 0.7397\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 41s 270ms/step - loss: 0.2322 - accuracy: 0.9030 - val_loss: 1.0651 - val_accuracy: 0.7404\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 44s 292ms/step - loss: 0.2303 - accuracy: 0.9052 - val_loss: 1.0749 - val_accuracy: 0.7365\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 43s 287ms/step - loss: 0.2319 - accuracy: 0.9037 - val_loss: 1.0729 - val_accuracy: 0.7432\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 44s 297ms/step - loss: 0.2321 - accuracy: 0.9038 - val_loss: 1.0764 - val_accuracy: 0.7387\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.2296 - accuracy: 0.9060 - val_loss: 1.0756 - val_accuracy: 0.7375\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 42s 281ms/step - loss: 0.2268 - accuracy: 0.9074 - val_loss: 1.0985 - val_accuracy: 0.7388\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 41s 273ms/step - loss: 0.2289 - accuracy: 0.9050 - val_loss: 1.0968 - val_accuracy: 0.7358\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 43s 286ms/step - loss: 0.2273 - accuracy: 0.9049 - val_loss: 1.1003 - val_accuracy: 0.7331\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 37s 245ms/step - loss: 0.2287 - accuracy: 0.9056 - val_loss: 1.1000 - val_accuracy: 0.7364\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 41s 277ms/step - loss: 0.2292 - accuracy: 0.9062 - val_loss: 1.0979 - val_accuracy: 0.7348\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 40s 264ms/step - loss: 0.2254 - accuracy: 0.9067 - val_loss: 1.1094 - val_accuracy: 0.7399\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 41s 273ms/step - loss: 0.2273 - accuracy: 0.9061 - val_loss: 1.0914 - val_accuracy: 0.7402\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 45s 298ms/step - loss: 0.2262 - accuracy: 0.9061 - val_loss: 1.1020 - val_accuracy: 0.7394\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 41s 271ms/step - loss: 0.2271 - accuracy: 0.9053 - val_loss: 1.1150 - val_accuracy: 0.7419\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 36s 240ms/step - loss: 0.2253 - accuracy: 0.9067 - val_loss: 1.1168 - val_accuracy: 0.7372\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 42s 277ms/step - loss: 0.2250 - accuracy: 0.9062 - val_loss: 1.1099 - val_accuracy: 0.7387\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 40s 268ms/step - loss: 0.2240 - accuracy: 0.9076 - val_loss: 1.1234 - val_accuracy: 0.7375\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 39s 260ms/step - loss: 0.2256 - accuracy: 0.9060 - val_loss: 1.1253 - val_accuracy: 0.7381\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 36s 243ms/step - loss: 0.2218 - accuracy: 0.9055 - val_loss: 1.1174 - val_accuracy: 0.7359\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 41s 273ms/step - loss: 0.2235 - accuracy: 0.9067 - val_loss: 1.1193 - val_accuracy: 0.7394\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 41s 275ms/step - loss: 0.2219 - accuracy: 0.9088 - val_loss: 1.1214 - val_accuracy: 0.7383\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 41s 277ms/step - loss: 0.2227 - accuracy: 0.9078 - val_loss: 1.1257 - val_accuracy: 0.7404\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 40s 265ms/step - loss: 0.2232 - accuracy: 0.9075 - val_loss: 1.1208 - val_accuracy: 0.7389\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 41s 270ms/step - loss: 0.2184 - accuracy: 0.9090 - val_loss: 1.1401 - val_accuracy: 0.7347\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 38s 253ms/step - loss: 0.2215 - accuracy: 0.9069 - val_loss: 1.1430 - val_accuracy: 0.7364\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 40s 268ms/step - loss: 0.2193 - accuracy: 0.9079 - val_loss: 1.1497 - val_accuracy: 0.7363\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 42s 280ms/step - loss: 0.2203 - accuracy: 0.9080 - val_loss: 1.1471 - val_accuracy: 0.7364\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 41s 274ms/step - loss: 0.2199 - accuracy: 0.9090 - val_loss: 1.1581 - val_accuracy: 0.7372\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 41s 275ms/step - loss: 0.2188 - accuracy: 0.9084 - val_loss: 1.1522 - val_accuracy: 0.7356\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 20\n",
    "lstm_out = 15\n",
    "max_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embed_dim, input_length = max_len))\n",
    "model.add(LSTM(lstm_out, dropout=0.2))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "model.fit(X_train, y_train, epochs = 100, batch_size = 128, validation_data = (X_test, y_test))\n",
    "model.save('sentiment_analyzer.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75      3403\n",
      "           1       0.65      0.75      0.69      2285\n",
      "           2       0.78      0.74      0.76      2517\n",
      "\n",
      "    accuracy                           0.74      8205\n",
      "   macro avg       0.73      0.74      0.73      8205\n",
      "weighted avg       0.74      0.74      0.74      8205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, axis = 1), np.argmax(y_pre, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
